{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge MDI343 : Sparse Score Fusion for Classifying Mate Pairs of Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1. Data loading and function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported package are as follows:\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running time of each algorithm (in milliseconds)\n",
    "\n",
    "alg_times = np.zeros((14, 1))\n",
    "alg_times[0] = 163\n",
    "alg_times[1] = 163\n",
    "alg_times[2] = 190\n",
    "alg_times[3] = 190\n",
    "alg_times[4] = 206\n",
    "alg_times[5] = 206\n",
    "alg_times[6] = 120\n",
    "alg_times[7] = 120\n",
    "alg_times[8] = 83\n",
    "alg_times[9] = 83\n",
    "alg_times[10] = 83\n",
    "alg_times[11] = 83\n",
    "alg_times[12] = 170\n",
    "alg_times[13] = 170\n",
    "\n",
    "# Time constraint: The total duration of the algorithms cannot exceed 600 milliseconds\n",
    "alg_time_thr = 600\n",
    "\n",
    "\n",
    "# Compute the total computational time for the fusion algorithm\n",
    "def compute_total_time(M):\n",
    "    is_used = np.zeros((14, 1))\n",
    "    for i in range(15):\n",
    "        for j in range(15):\n",
    "            if(M[i, j] != 0):\n",
    "                if(i >= 1):\n",
    "                    is_used[i - 1] = 1\n",
    "                if(j >= 1):\n",
    "                    is_used[j - 1] = 1\n",
    "\n",
    "    total_dur = np.dot(is_used.T, alg_times)\n",
    "    return total_dur[0, 0]\n",
    "\n",
    "# Evaluation metric\n",
    "\n",
    "\n",
    "def compute_eval(fused_score):\n",
    "    look_at_FAR = 0.0001\n",
    "    # calculating FAR and FRR\n",
    "    sort = np.argsort(fused_score[:, 1])\n",
    "\n",
    "    #sort = np.concatenate([sort[-2:],sort[:-2]], axis=0)\n",
    "    scores = fused_score[sort]\n",
    "    totpos = sum(scores[:, 0])\n",
    "    totneg = scores.shape[0] - totpos\n",
    "    fa = (np.cumsum(scores[:, 0] - 1) + totneg) / totneg\n",
    "    fr = np.cumsum(scores[:, 0]) / totpos\n",
    "\n",
    "    i = 0\n",
    "    while fa[i] > look_at_FAR:\n",
    "        i += 1\n",
    "\n",
    "    return scores[i][1], fa[i], fr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "train_fname = 'train15_telecom.txt'\n",
    "train_data = np.loadtxt(train_fname, dtype=np.float)\n",
    "# The first column contains the labels, the rest of the columns contains the scores\n",
    "\n",
    "# Extract the labels\n",
    "y_trn = train_data[:, 0].astype(int)\n",
    "\n",
    "# Extract the score vectors\n",
    "s_trn = train_data.copy()\n",
    "s_trn[:, 0] = 1;\n",
    "\n",
    "# Assign the training dataset and corresponding labels\n",
    "X, y = s_trn, y_trn\n",
    "X[X == -float(\"inf\")] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2. Feature analysis and comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b3f0240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate and visualize the correlation among algorithms\n",
    "corr = pd.DataFrame(X).corr()\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "plt.imshow(corr)\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(corr.columns)), corr.columns)\n",
    "plt.yticks(range(len(corr.columns)), corr.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It is seen that these pair algorithms are reletively corelated: Algo1 and 2, Algo3 and 4, algo5 and 6, Algo7 and 8, Algo9 and 10, Algo11 and 12, Algo13 and 14. That is possible due to these pair algorithms have used similar evaluation method. Thus for constructing a better combinason amaong all those algorithme, it would be better to use only one of the corelated algorithm pair as mentioned before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 13 (0.146765)\n",
      "2. feature 7 (0.138985)\n",
      "3. feature 8 (0.121416)\n",
      "4. feature 14 (0.105819)\n",
      "5. feature 2 (0.093915)\n",
      "6. feature 1 (0.091977)\n",
      "7. feature 3 (0.072960)\n",
      "8. feature 6 (0.071967)\n",
      "9. feature 5 (0.058427)\n",
      "10. feature 4 (0.045028)\n",
      "11. feature 12 (0.026641)\n",
      "12. feature 9 (0.015857)\n",
      "13. feature 11 (0.009708)\n",
      "14. feature 10 (0.000534)\n",
      "15. feature 0 (0.000000)\n"
     ]
    }
   ],
   "source": [
    "# Feature importance analysis by logistic regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X, y)\n",
    "importances = abs(np.std(X, 0) * lr.coef_)\n",
    "importances = [float(i) / sum(importances[0]) for i in importances[0]]\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = np.array(importances)\n",
    "plt.figure(figsize=(12,8)) \n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],color=\"b\", align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 8 (0.168697)\n",
      "2. feature 13 (0.160891)\n",
      "3. feature 12 (0.114658)\n",
      "4. feature 9 (0.113258)\n",
      "5. feature 14 (0.108318)\n",
      "6. feature 3 (0.082350)\n",
      "7. feature 7 (0.067076)\n",
      "8. feature 5 (0.054746)\n",
      "9. feature 11 (0.053710)\n",
      "10. feature 1 (0.033715)\n",
      "11. feature 10 (0.015786)\n",
      "12. feature 2 (0.015317)\n",
      "13. feature 4 (0.006275)\n",
      "14. feature 6 (0.005204)\n",
      "15. feature 0 (0.000000)\n"
     ]
    }
   ],
   "source": [
    "# Feature importance analysis  by ensemble learning\n",
    "forest = ExtraTreesClassifier()\n",
    "forest.fit(X, y)\n",
    "importances = forest.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8)) \n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],color=\"r\", align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results of feature importance analysis by logistic regression and extra tree are not exactly the same. But in global, il it found that the algo 7, 8, 13, 14 are relitively having more weigh than other algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if only algorithm 1 :, threshold : 5023.26 far : 9.9610468009e-05 frr : 0.253079046817\n",
      "if only algorithm 2 :, threshold : 5029.01 far : 9.9610468009e-05 frr : 0.253079046817\n",
      "if only algorithm 3 :, threshold : 5028.1 far : 9.9610468009e-05 frr : 0.255898650898\n",
      "if only algorithm 4 :, threshold : 5032.16 far : 9.9610468009e-05 frr : 0.255898650898\n",
      "if only algorithm 5 :, threshold : 4906.89 far : 9.9610468009e-05 frr : 0.231109631689\n",
      "if only algorithm 6 :, threshold : 4952.24 far : 9.9610468009e-05 frr : 0.231109631689\n",
      "if only algorithm 7 :, threshold : 5002.08 far : 9.9610468009e-05 frr : 0.165397192144\n",
      "if only algorithm 8 :, threshold : 5015.17 far : 9.9610468009e-05 frr : 0.165397192144\n",
      "if only algorithm 9 :, threshold : 4659.33 far : 9.9610468009e-05 frr : 0.174090971393\n",
      "if only algorithm 10 :, threshold : 4782.7 far : 9.9610468009e-05 frr : 0.174090971393\n",
      "if only algorithm 11 :, threshold : 4949.0 far : 9.9610468009e-05 frr : 0.313034794698\n",
      "if only algorithm 12 :, threshold : 4980.23 far : 9.9610468009e-05 frr : 0.313034794698\n",
      "if only algorithm 13 :, threshold : 5219.04 far : 9.9610468009e-05 frr : 0.163027941493\n",
      "if only algorithm 14 :, threshold : 5154.23 far : 9.9610468009e-05 frr : 0.163027941493\n"
     ]
    }
   ],
   "source": [
    "# Test the performance of each algorithm.\n",
    "\n",
    "for i in range(1, 15):\n",
    "    M = np.zeros((15, 15))\n",
    "    M[0, i] = 1\n",
    "    fuse = np.multiply(s_trn[:, None, :] * s_trn[:, :, None], M)\n",
    "    fuse = np.concatenate([np.reshape(\n",
    "        y_trn, [-1, 1]), np.reshape(np.sum(fuse, axis=(1, 2)), [-1, 1])], axis=1)\n",
    "    fuse[np.isnan(fuse)] = -float(\"inf\")\n",
    "\n",
    "    # compute the FRR at FAR = 0.01%\n",
    "    thr, fa, fr = compute_eval(fuse)\n",
    "    look_at_FAR = 0.0001\n",
    "    print(\"if only algorithm\", i, \":, threshold :\",\n",
    "          thr, \"far :\", fa, \"frr :\", fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This result corresponds well with the former correlation analysis among features. The errors \"frr\" are almost the same for each pair algorithm, ie Algo1 and 2, ... ,Algo13 and 14. What's more, it shows that Algo 7, 8, 9, 10, 13, 14 display better performance, this is also consistent with the conclusion from feature importance anamysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3. Variable construction and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible combinations :  16384\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alg1</th>\n",
       "      <th>alg2</th>\n",
       "      <th>alg3</th>\n",
       "      <th>alg4</th>\n",
       "      <th>alg5</th>\n",
       "      <th>alg6</th>\n",
       "      <th>alg7</th>\n",
       "      <th>alg8</th>\n",
       "      <th>alg9</th>\n",
       "      <th>alg10</th>\n",
       "      <th>alg11</th>\n",
       "      <th>alg12</th>\n",
       "      <th>alg13</th>\n",
       "      <th>alg14</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  alg1 alg2 alg3 alg4 alg5 alg6 alg7 alg8 alg9 alg10 alg11 alg12 alg13 alg14  \\\n",
       "0    1    1    1    0    0    0    0    0    1     0     0     0     0     0   \n",
       "1    1    1    1    0    0    0    0    0    0     1     0     0     0     0   \n",
       "2    1    1    1    0    0    0    0    0    0     0     1     0     0     0   \n",
       "3    1    1    1    0    0    0    0    0    0     0     0     1     0     0   \n",
       "4    1    1    1    0    0    0    0    0    0     0     0     0     0     0   \n",
       "\n",
       "  time  \n",
       "0  599  \n",
       "1  599  \n",
       "2  599  \n",
       "3  599  \n",
       "4  516  "
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate how much possible combinations among 14 algorithms\n",
    "comb = [[True], [False]]\n",
    "for i in range(14 - 1):\n",
    "    comb_tmp = []\n",
    "    for j in range(len(comb)):\n",
    "        comb_tmp += [comb[j] + [True], comb[j] + [False]]\n",
    "    comb = comb_tmp\n",
    "print('Possible combinations : ', len(comb))  # (16384 combinations)\n",
    "\n",
    "# Create a dataframe with all possible combinations\n",
    "\n",
    "df = pd.DataFrame(data=comb, columns=['alg1', 'alg2', 'alg3', 'alg4', 'alg5',\n",
    "                                      'alg6', 'alg7', 'alg8', 'alg9', 'alg10', 'alg11', 'alg12', 'alg13', 'alg14'])\n",
    "df = df * 1\n",
    "df[\"time\"] = np.dot(df, alg_times)\n",
    "\n",
    "# Remove the combinations that exceed duration 600 milliseconds\n",
    "\n",
    "df = df[df[\"time\"] <= 600]  # (1024 combinations)\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the combinations which have been included in other combinaton.\n",
    "# That is to say, find subsets among those combination\n",
    "\n",
    "comb_to_red = []\n",
    "for i in range(df.shape[0]):\n",
    "    for j in range(df.shape[0]):\n",
    "        if i != j:\n",
    "            if (df.iloc[i, :14] >= df.iloc[j, :14]).all():\n",
    "                comb_to_red.append(j)\n",
    "comb_to_red = np.unique(comb_to_red)\n",
    "\n",
    "list(comb_to_red)\n",
    "df = df.drop(comb_to_red)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# df.shape = (577, 15), now we have reduced possible combinations from 1204 to 577"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate error \"frr\" for each combinations in dataframe df\n",
    "# The coefficent for these combinations are simply identificly given, ie 1\n",
    "\n",
    "df[\"error\"] = 0\n",
    "for i in range(df.shape[0]):\n",
    "    M = np.zeros((15, 15))\n",
    "    M[0, 1:] = df.iloc[i][:14]\n",
    "    fuse = np.multiply(s_trn[:, None, :] * s_trn[:, :, None], M)\n",
    "    fuse = np.concatenate([np.reshape(\n",
    "        y_trn, [-1, 1]), np.reshape(np.sum(fuse, axis=(1, 2)), [-1, 1])], axis=1)\n",
    "    fuse[np.isnan(fuse)] = -float(\"inf\")\n",
    "\n",
    "    # compute the FRR at FAR = 0.01%\n",
    "    thr, fa, fr = compute_eval(fuse)\n",
    "    # print(i, fr)\n",
    "    df[\"error\"][i] = fr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then the intersting algorithm combinations are filtered according their error \"frr\", those with 10 least errors are selected. They will be applied an optimization function to find the best coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = df.sort_values(by=['error'])[:10]\n",
    "df_refined = df_selected.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4: Optimization of combination coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function which minimize the error \"frr\"\n",
    "def combcoef(coef):\n",
    "\n",
    "    M = np.zeros((15, 15))\n",
    "    M[0, index[0]] = coef[0]\n",
    "    M[0, index[1]] = coef[0]\n",
    "    M[0, index[2]] = coef[1]\n",
    "    M[0, index[3]] = coef[2]\n",
    "    M[0, index[4]] = coef[3]\n",
    "\n",
    "    look_at_FAR = 0.0001\n",
    "    # calculating FAR and FRR\n",
    "    fuse = np.multiply(s_trn[:, None, :] * s_trn[:, :, None], M)\n",
    "    fuse = np.concatenate([np.reshape(\n",
    "        y_trn, [-1, 1]), np.reshape(np.sum(fuse, axis=(1, 2)), [-1, 1])], axis=1)\n",
    "    fuse[np.isnan(fuse)] = -float(\"inf\")\n",
    "    sort = np.argsort(fuse[:, 1])\n",
    "\n",
    "    #sort = np.concatenate([sort[-2:],sort[:-2]], axis=0)\n",
    "    scores = fuse[sort]\n",
    "    totpos = sum(scores[:, 0])\n",
    "    totneg = scores.shape[0] - totpos\n",
    "    fa = (np.cumsum(scores[:, 0] - 1) + totneg) / totneg\n",
    "    fr = np.cumsum(scores[:, 0]) / totpos\n",
    "\n",
    "    i = 0\n",
    "    while fa[i] > look_at_FAR:\n",
    "        i += 1\n",
    "    # print(fr[i])\n",
    "    return fr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the optimization function to find the best coefficent to each potential combination\n",
    "\n",
    "coef_list = []\n",
    "for comb in range(df_refined.shape[0]):\n",
    "    coef0 = [1, 1, 1, 1, 1]\n",
    "    index = []\n",
    "    for alg in range(14):\n",
    "        if df_refined.iloc[comb, alg] != 0:\n",
    "            index.append(alg + 1)\n",
    "    # print(index)\n",
    "    # print(df_refined.iloc[comb, :14], \":\")\n",
    "    res = minimize(combcoef, coef0, args=(), method=\"COBYLA\",\n",
    "                   jac=None, hess=None, hessp=None, tol=None, callback=None)\n",
    "    # print(res.x)\n",
    "    coef_list.append(res.x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect optimized coefficients into dataframe\n",
    "\n",
    "for comb in range(df_refined.shape[0]):\n",
    "    ind = 0\n",
    "    for alg in range(14):\n",
    "        if df_refined.iloc[comb, alg] != 0:\n",
    "            df_refined.iloc[comb, alg] = coef_list[comb][ind]\n",
    "            ind = ind + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 5: Validation and conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alg1</th>\n",
       "      <th>alg2</th>\n",
       "      <th>alg3</th>\n",
       "      <th>alg4</th>\n",
       "      <th>alg5</th>\n",
       "      <th>alg6</th>\n",
       "      <th>alg7</th>\n",
       "      <th>alg8</th>\n",
       "      <th>alg9</th>\n",
       "      <th>alg10</th>\n",
       "      <th>alg11</th>\n",
       "      <th>alg12</th>\n",
       "      <th>alg13</th>\n",
       "      <th>alg14</th>\n",
       "      <th>time</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.97863</td>\n",
       "      <td>0.92145</td>\n",
       "      <td>1.01491</td>\n",
       "      <td>0.992821</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.906982</td>\n",
       "      <td>539</td>\n",
       "      <td>0.082473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.633101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.641464</td>\n",
       "      <td>0.742667</td>\n",
       "      <td>0.814128</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>539</td>\n",
       "      <td>0.083198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.562156</td>\n",
       "      <td>0</td>\n",
       "      <td>0.599002</td>\n",
       "      <td>1.03809</td>\n",
       "      <td>0</td>\n",
       "      <td>0.905884</td>\n",
       "      <td>0</td>\n",
       "      <td>0.984055</td>\n",
       "      <td>539</td>\n",
       "      <td>0.083629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.48445</td>\n",
       "      <td>1.02796</td>\n",
       "      <td>2.02084</td>\n",
       "      <td>0</td>\n",
       "      <td>1.99793</td>\n",
       "      <td>0</td>\n",
       "      <td>0.996331</td>\n",
       "      <td>539</td>\n",
       "      <td>0.083648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.851942</td>\n",
       "      <td>0</td>\n",
       "      <td>1.02801</td>\n",
       "      <td>1.19234</td>\n",
       "      <td>0.926618</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>539</td>\n",
       "      <td>0.083766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.79514</td>\n",
       "      <td>2.28029</td>\n",
       "      <td>2.08815</td>\n",
       "      <td>0</td>\n",
       "      <td>1.30657</td>\n",
       "      <td>0</td>\n",
       "      <td>1.02888</td>\n",
       "      <td>0</td>\n",
       "      <td>576</td>\n",
       "      <td>0.084921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00705</td>\n",
       "      <td>0</td>\n",
       "      <td>0.993355</td>\n",
       "      <td>1.85703</td>\n",
       "      <td>0</td>\n",
       "      <td>1.17096</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>539</td>\n",
       "      <td>0.086527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750372</td>\n",
       "      <td>2.21014</td>\n",
       "      <td>1.55685</td>\n",
       "      <td>0</td>\n",
       "      <td>1.40503</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99457</td>\n",
       "      <td>576</td>\n",
       "      <td>0.087388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.43542</td>\n",
       "      <td>1.23062</td>\n",
       "      <td>1.95381</td>\n",
       "      <td>0</td>\n",
       "      <td>0.957369</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>539</td>\n",
       "      <td>0.089640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.533291</td>\n",
       "      <td>0.429814</td>\n",
       "      <td>0.52981</td>\n",
       "      <td>0.355249</td>\n",
       "      <td>0</td>\n",
       "      <td>0.956879</td>\n",
       "      <td>0</td>\n",
       "      <td>539</td>\n",
       "      <td>0.090932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  alg1 alg2 alg3 alg4 alg5 alg6      alg7      alg8      alg9     alg10  \\\n",
       "0    0    0    0    0    0    0         0   0.97863   0.92145   1.01491   \n",
       "1    0    0    0    0    0    0  0.633101         0  0.641464  0.742667   \n",
       "4    0    0    0    0    0    0  0.562156         0  0.599002   1.03809   \n",
       "7    0    0    0    0    0    0         0   1.48445   1.02796   2.02084   \n",
       "3    0    0    0    0    0    0  0.851942         0   1.02801   1.19234   \n",
       "9    0    0    0    0    0    0   0.79514   2.28029   2.08815         0   \n",
       "5    0    0    0    0    0    0   1.00705         0  0.993355   1.85703   \n",
       "8    0    0    0    0    0    0  0.750372   2.21014   1.55685         0   \n",
       "6    0    0    0    0    0    0         0   1.43542   1.23062   1.95381   \n",
       "2    0    0    0    0    0    0         0  0.533291  0.429814   0.52981   \n",
       "\n",
       "      alg11     alg12     alg13     alg14 time     error  \n",
       "0  0.992821         0         0  0.906982  539  0.082473  \n",
       "1  0.814128         0         1         0  539  0.083198  \n",
       "4         0  0.905884         0  0.984055  539  0.083629  \n",
       "7         0   1.99793         0  0.996331  539  0.083648  \n",
       "3  0.926618         0         0         1  539  0.083766  \n",
       "9   1.30657         0   1.02888         0  576  0.084921  \n",
       "5         0   1.17096         1         0  539  0.086527  \n",
       "8   1.40503         0         0   0.99457  576  0.087388  \n",
       "6         0  0.957369         1         0  539  0.089640  \n",
       "2  0.355249         0  0.956879         0  539  0.090932  "
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate error \"frr\" with those optimized cofficients for training data\n",
    "\n",
    "M_refined_all = []\n",
    "for i in range(df_refined.shape[0]):\n",
    "    M = np.zeros((15, 15))\n",
    "    M[0, 1:] = df_refined.iloc[i][:14]\n",
    "    M_refined_all.append(M)\n",
    "\n",
    "    fuse = np.multiply(s_trn[:, None, :] * s_trn[:, :, None], M)\n",
    "    fuse = np.concatenate([np.reshape(\n",
    "        y_trn, [-1, 1]), np.reshape(np.sum(fuse, axis=(1, 2)), [-1, 1])], axis=1)\n",
    "    fuse[np.isnan(fuse)] = -float(\"inf\")\n",
    "\n",
    "    # compute the FRR at FAR = 0.01%\n",
    "    thr, fa, fr = compute_eval(fuse)\n",
    "    df_refined.iloc[i, 15] = fr\n",
    "    # print(\"for comb\",i+1,\":\", \"fr =\", fr)\n",
    "\n",
    "df_refined = df_refined.reset_index(drop=True)\n",
    "df_refined.sort_values(by=\"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Those coefficients are generally validated for training data, except the combination 3, ie combination among Algo 8, 9, 10, 11, 13. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission\n",
    "\n",
    "# Write the matrix M to the disk:\n",
    "\n",
    "for M in range(len(M_refined_all)):\n",
    "    np.savetxt('M_pred_' + str(M + 1) + '.txt', M_refined_all[M], fmt='%f')\n",
    "\n",
    "# M_pred_1.txt => 0.0710172744722\n",
    "# M_pred_2.txt => 0.0753358925144\n",
    "# M_pred_3.txt => 0.0830134357006\n",
    "# M_pred_4.txt => 0.0681381957774\n",
    "# M_pred_5.txt => 0.0714971209213\n",
    "# M_pred_6.txt => 0.0690978886756\n",
    "# M_pred_7.txt => 0.0700575815739\n",
    "# M_pred_8.txt => 0.0724568138196\n",
    "# M_pred_9.txt => 0.0748560460653\n",
    "# M_pred_10.txt => 0.0734165067179"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The validation for test data are mainly consistent to the result from training data. Algorithm combination 3 displays the worst classification among the 10 selected combinations. The others are a little homogenous, but in termes of test validation, the combination 4, composed of Algo 7, 9, 10, 11, 14 has the best classification performance.\n",
    "\n",
    "#### Through this challenge, we can see the advantage that confusion matrix methods offers better target detection performance. Compared with one best algorithm, ie Algo 7 or 8, which gives frr around 0.1653, finaly we reached the frr to about 0.0681, where over the half of frr has been reduced by comfusion method. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
