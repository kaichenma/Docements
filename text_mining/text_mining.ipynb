{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP Text mining - Kaichen MA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application à la classification : l’analyse d’opinions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implémentation du classifieur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from collections import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n",
      "2000 documents\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Load data\n",
    "print(\"Loading dataset\")\n",
    "\n",
    "from glob import glob\n",
    "filenames_neg = sorted(glob(op.join('.', 'data', 'imdb1', 'neg', '*.txt')))\n",
    "filenames_pos = sorted(glob(op.join('.', 'data', 'imdb1', 'pos', '*.txt')))\n",
    "\n",
    "texts_neg = [open(f).read() for f in filenames_neg]\n",
    "texts_pos = [open(f).read() for f in filenames_pos]\n",
    "texts = texts_neg + texts_pos\n",
    "y = np.ones(len(texts), dtype=np.int)\n",
    "y[:len(texts_neg)] = 0.\n",
    "\n",
    "print(\"%d documents\" % len(texts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Compléter la fonction count_words qui va compter le nombre d’occurrences de chaque mot dans une liste de string et renvoyer le vocabulaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(texts,stop_words=None):\n",
    "    \"\"\"\n",
    "    Vectorize text : return count of each word in the text snippets\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    texts : list of str\n",
    "        The texts\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    vocabulary : dict\n",
    "        A dictionary that points to an index in counts for each word.\n",
    "    counts : ndarray, shape (n_samples, n_features)\n",
    "        The counts of each word in each text.\n",
    "        n_samples == number of documents.\n",
    "        n_features == number of words in vocabulary.\n",
    "    \"\"\"\n",
    "\n",
    "    words = set()\n",
    "    \n",
    "    if stop_words is None:\n",
    "        \n",
    "        for i in range(len(texts)):\n",
    "            for j in re.findall(r\"(\\w+)\", texts[i]):\n",
    "                words.add(j)\n",
    "        \n",
    "        vocabulary = dict(zip(words, range(len(words)))) \n",
    "        counts = np.zeros((len(texts), len(words)), dtype=int)\n",
    "        for i in range(len(texts)):\n",
    "            # occurrence de mot dans chaque texte\n",
    "            for j in re.findall(r\"(\\w+)\", texts[i]):\n",
    "                counts[i, vocabulary[j]] += 1        \n",
    "                    \n",
    "    else:\n",
    "        \n",
    "        for i in range(len(texts)):\n",
    "            for j in re.findall(r\"(\\w+)\", texts[i]):\n",
    "                if j not in stop_words:\n",
    "                    words.add(j)\n",
    "                    \n",
    "        vocabulary = dict(zip(words, range(len(words)))) \n",
    "        counts = np.zeros((len(texts), len(words)), dtype=int)\n",
    "        for i in range(len(texts)):\n",
    "            # occurrence de mot dans chaque texte\n",
    "            for j in re.findall(r\"(\\w+)\", texts[i]):\n",
    "                if j not in stop_words:\n",
    "                    counts[i, vocabulary[j]] += 1                  \n",
    "                    \n",
    "    \n",
    "\n",
    "    n_features = len(vocabulary)\n",
    "  \n",
    "    return vocabulary, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 39696)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary, X = count_words(texts)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Expliquer comment les classes positives et négatives ont été assignées sur les critiques de films "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les commentaires ont été classés positif ou négatif selon l'indicateur explicite dans le texte, tel que les fractions (ex: 8/10), des étoiles (ex: 4/5), ou encore avec des lettres (A, B, C, D...)\n",
    "\n",
    "Pour une notation sur 5, les documents avec des notes suppérieures à 3.5 sont considérés comme positif et ceux avec des notes inférieures à 2 sont considérés comme négatif.\n",
    "\n",
    "Pour un système à 4 étoiles, les évaluations supérieurs ou égales à 3 sont classifiés positives, et celles inférieurs ou égales à 1.5 sont considérées négatives.\n",
    "\n",
    "Pour un système de botes par lettre, B ou au-dessus est marqué positive, C ou au-dessous est classifié négatif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Compléter la classe NB pour qu’elle implémente le classifieur Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NB(BaseEstimator, ClassifierMixin):\n",
    "           \n",
    "\n",
    "    def __init__(self): \n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples = X.shape[0]\n",
    "        n_features = X.shape[1]\n",
    "        N = len(X)\n",
    "        classes = np.unique(y)\n",
    "        self.classe_ = list(set(y))\n",
    "        self.prior_ = {}\n",
    "        self.condprob_ = np.zeros([X.shape[1] , len(classes)])\n",
    "    \n",
    "        for c in classes:\n",
    "            X_classe = X[y == c]\n",
    "            Nc = X_classe.shape[0]\n",
    "            self.prior_[c] = Nc / N\n",
    "            tct = X_classe.sum(axis=0) + 1 \n",
    "            self.condprob_[:, c] = tct / np.sum(tct)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        score = np.zeros(len(self.classe_))\n",
    "        log_prior = np.log(list(self.prior_.values())) \n",
    "        log_condprob = np.log(self.condprob_)\n",
    "        score = log_prior\n",
    "        for i in range(X.shape[0]):\n",
    "            W_ind = np.where(X[i])[0]\n",
    "            W = np.repeat(W_ind, X[i,W_ind])\n",
    "            for j in range(len(self.classe_)):\n",
    "                score[j] = np.sum(log_condprob[W, j])\n",
    "            y_pred[i] = np.argmax(score)\n",
    "        return y_pred\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return np.mean(self.predict(X) == y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification score with NB class is: 0.812\n"
     ]
    }
   ],
   "source": [
    "clf_nb = NB()\n",
    "clf_nb.fit(X[::2], y[::2])\n",
    "print('Classification score with NB class is: %s' % (clf_nb.score(X[1::2], y[1::2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Evaluer les performances de votre classifieur en cross-validation 5-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of cross validation fold 1 is: 0.81\n",
      "The score of cross validation fold 2 is: 0.825\n",
      "The score of cross validation fold 3 is: 0.8125\n",
      "The score of cross validation fold 4 is: 0.83\n",
      "The score of cross validation fold 5 is: 0.7925\n",
      "The score of NB classe with cross validation 5-folds is : 0.814\n"
     ]
    }
   ],
   "source": [
    "score_nb = cross_val_score(clf_nb, X, y, cv = 5, n_jobs=-1)\n",
    "for i in range(len(score_nb)):\n",
    "    print (\"The score of cross validation fold\",i+1,\"is:\", score_nb[i])\n",
    "\n",
    "print(\"The score of NB classe with cross validation 5-folds is :\", score_nb.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Modifiez la fonction count_words pour qu’elle ignore les “stop words”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = open('./data/english.stop').read().replace('\\n',' ').split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 39195)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_reduced, X_reduced = count_words(texts,stop_words=stopWords)\n",
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification score with NB class without stop words is: 0.804\n"
     ]
    }
   ],
   "source": [
    "clf_nb = NB()\n",
    "clf_nb.fit(X_reduced[::2], y[::2])\n",
    "print('Classification score with NB class without stop words is: %s' % (clf_nb.score(X_reduced[1::2], y[1::2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La performance de notre classifieur NB baisse un petit peu (de 0.812 à 0.804) sans les mots stop_words. On trouve que le fichier stop_words quand même inclut certains des mots significatifs tels que awfully, best, better, clearly, definitely. La suppression des mots pourrait rendre les critiques moins identifiables dans leur négativité ou positivité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation de scikitlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Comparer votre implémentation avec scikitlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification score with NB class and analyzer='char' is : 0.606\n"
     ]
    }
   ],
   "source": [
    "# Set analyzer = 'char' for CountVectorizer, \n",
    "pipe_NB = Pipeline([('countVectorizer',CountVectorizer(analyzer='char')),\\\n",
    "                    ('clf',MultinomialNB())])\n",
    "pipe_NB.fit(texts[::2],y[::2])\n",
    "print(\"Classification score with NB class and analyzer='char' is :\", \\\n",
    "      pipe_NB.score(texts[1::2],y[1::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification score with NB class and analyzer='char', ngram_range=(1,2) is : 0.658\n"
     ]
    }
   ],
   "source": [
    "# Set analyzer = 'char' for CountVectorizer\n",
    "pipe_NB = Pipeline([('countVectorizer',CountVectorizer(analyzer='char', ngram_range=(1,2))),\\\n",
    "                    ('clf',MultinomialNB())])\n",
    "pipe_NB.fit(texts[::2],y[::2])\n",
    "print(\"Classification score with NB class and analyzer='char', ngram_range=(1,2) is :\", \\\n",
    "      pipe_NB.score(texts[1::2],y[1::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification score with NB class and analyzer='word' is : 0.813\n"
     ]
    }
   ],
   "source": [
    "# Set analyzer = 'word' for CountVectorizer\n",
    "pipe_NB = Pipeline([('countVectorizer',CountVectorizer(analyzer='word')),\\\n",
    "                    ('clf',MultinomialNB())])\n",
    "pipe_NB.fit(texts[::2],y[::2])\n",
    "print(\"Classification score with NB class and analyzer='word' is :\",\\\n",
    "      pipe_NB.score(texts[1::2],y[1::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification score with NB class and analyzer='word', ngram_range=(1,2) is : 0.841\n"
     ]
    }
   ],
   "source": [
    "# Set analyzer = 'word' for CountVectorizer\n",
    "pipe_NB = Pipeline([('countVectorizer',CountVectorizer(analyzer='word',ngram_range=(1,2))),\\\n",
    "                    ('clf',MultinomialNB())])\n",
    "pipe_NB.fit(texts[::2],y[::2])\n",
    "print(\"Classification score with NB class and analyzer='word', ngram_range=(1,2) is :\", \\\n",
    "      pipe_NB.score(texts[1::2],y[1::2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selon les essais au-dessus, l'analyseur de CountVectorizer \"word\" est trouvé plus beaucoup plus performant que \"char\". En plus, Le traitement autorisant les mots et bigrammes améliore les performances de classifieur pour ces deux façons de CountVectorizer. Notamment la classfieur Naive Bayes avec le bigrammes ngram_range, sa performance arrive 0.841.\n",
    "\n",
    "Au niveau de la performance de la classifieur de sickitlearn et celui fait dans le cadre de ce TP, on observe que ces efficacités sont bien proches (0.813 vs 0.812).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Tester un autre algorithme de la librairie scikitlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification score with LinearSVC and is : 0.81\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "pipe_SVC = Pipeline([('countVectorizer',CountVectorizer()),\\\n",
    "                    ('clf',LinearSVC())])\n",
    "pipe_SVC.fit(texts[::2],y[::2])\n",
    "print(\"Classification score with LinearSVC and is :\", \\\n",
    "      pipe_SVC.score(texts[1::2],y[1::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification score with LinearSVC and ngram_range=(1,2) is : 0.825\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "pipe_SVC = Pipeline([('countVectorizer',CountVectorizer(ngram_range=(1,2))),\\\n",
    "                    ('clf',LinearSVC())])\n",
    "pipe_SVC.fit(texts[::2],y[::2])\n",
    "print(\"Classification score with LinearSVC and ngram_range=(1,2) is :\", \\\n",
    "      pipe_SVC.score(texts[1::2],y[1::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification score with LogisticRegression is : 0.831\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe_LR = Pipeline([('countVectorizer', CountVectorizer()),\\\n",
    "                    ('clf', LogisticRegression())])\n",
    "pipe_LR.fit(texts[::2],y[::2])\n",
    "print(\"Classification score with LogisticRegression is :\", \\\n",
    "      pipe_LR.score(texts[1::2],y[1::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification score with LogisticRegression and ngram_range=(1,2) is : 0.828\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe_LR = Pipeline([('countVectorizer', CountVectorizer(analyzer='word',ngram_range=(1,2))),\\\n",
    "                    ('clf', LogisticRegression())])\n",
    "pipe_LR.fit(texts[::2],y[::2])\n",
    "print(\"Classification score with LogisticRegression and ngram_range=(1,2) is :\", \\\n",
    "      pipe_LR.score(texts[1::2],y[1::2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on voit que globalement la performance de classifieur LogisticRegression est mieux que de classifieur LinearSVC. Par contre, l'appplication de bigramme ngram_range baisse un la performance de classifieur LogisticRegression (0.831 sans bigramme vs 0.828 avec bigramme)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Utiliser la librairie NLTK afin de procéder à une racinisation (stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import SnowballStemmer \n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def tokenizer_stemmer(texts):\n",
    "    p = re.compile('[\\s\\.:;,_]')\n",
    "    words = p.split(texts)\n",
    "    return [stemmer.stem(word) for word in words if word !='']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a test for function 'tokenizer_stemmer'\n",
    "tokenizer_stemmer(\"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification score of Naive Bayes with stemming is 0.807\n"
     ]
    }
   ],
   "source": [
    "pipe_stem = Pipeline([('countVectorizer', CountVectorizer(analyzer=tokenizer_stemmer)),\\\n",
    "                          ('clf', MultinomialNB())])\n",
    "\n",
    "pipe_stem.fit(texts[::2],y[::2])\n",
    "print(\"Classification score of Naive Bayes with stemming is\", \\\n",
    "      pipe_stem.score(texts[1::2],y[1::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification score of LogisticRegression with stemming is 0.829\n"
     ]
    }
   ],
   "source": [
    "pipe_stem = Pipeline([('countVectorizer', CountVectorizer(analyzer=tokenizer_stemmer)),\\\n",
    "                          ('clf', LogisticRegression())])\n",
    "\n",
    "pipe_stem.fit(texts[::2],y[::2])\n",
    "print(\"Classification score of LogisticRegression with stemming is\", \\\n",
    "      pipe_stem.score(texts[1::2],y[1::2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les performances de classifieur restent à peu près invariantes, ce pré-traitement de racinisation réduit la taille de nombre de feature et plus la taille de la matrice pour l'espace mémoire ou l'espace de stockage nécessaire.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Filtrer les mots par catégorie grammaticale (POS : Part Of Speech) et ne garder que les noms, les verbes, les adverbes et les adjectifs pour la classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_tag(texts):\n",
    "    \n",
    "    p = re.compile('[\\s\\.:;,_]')\n",
    "    words = p.split(texts)    \n",
    "    words_reduced = [word for word in words if word != '']   \n",
    "    tags = pos_tag(words_reduced)\n",
    "    return [tag[0] for tag in tags if tag[1] in ['NN', 'VBN', 'RB', 'JJ']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a test for function 'tokenizer_tag'\n",
    "tokenizer_tag(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification score of Naive Bayes with POS filting is 0.816\n"
     ]
    }
   ],
   "source": [
    "pipe_tag = Pipeline([('countVect', CountVectorizer(analyzer=tokenizer_tag)),\\\n",
    "                          ('naiveBayes', MultinomialNB())])\n",
    "\n",
    "\n",
    "pipe_tag.fit(texts[::2],y[::2])\n",
    "print(\"Classification score of Naive Bayes with POS filting is\", \\\n",
    "      pipe_tag.score(texts[1::2],y[1::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification score of LogisticRegression with POS filting is 0.83\n"
     ]
    }
   ],
   "source": [
    "pipe_tag = Pipeline([('countVect', CountVectorizer(analyzer=tokenizer_tag)),\\\n",
    "                          ('naiveBayes', LogisticRegression())])\n",
    "\n",
    "\n",
    "pipe_tag.fit(texts[::2],y[::2])\n",
    "print(\"Classification score of LogisticRegression with POS filting is\", \\\n",
    "      pipe_tag.score(texts[1::2],y[1::2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La filtrage des mots par catégorie grammaticale améliore les performances de classifieur pour Naive Bayes et LogisticRegression. \n",
    "L'extraction POS des noms, verbes, adverbes, et adjectifs permet de extraire les mots significatif, dont les mots clés sont plus visés. Ceci en plus reduit fortement le nombre de vocabulaire, Le temps de traitement de cette opération.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
